{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd9e692",
   "metadata": {},
   "source": [
    "## Dataset & prompt setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8274f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e14f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATASETS = 2\n",
    "\n",
    "DATASET_NAMES = ['sara', 'echr']\n",
    "\n",
    "sara_df = pd.read_csv('DATASETS/sara_annotated.csv')\n",
    "echr_df = pd.read_csv('DATASETS/echr_annotated.csv')\n",
    "\n",
    "DATASETS = [sara_df, echr_df]\n",
    "\n",
    "DATASET_NAME_TO_DATASET = {'sara': sara_df, 'echr': echr_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bae7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROMPTS = 9\n",
    "\n",
    "IN_CONTEXT_PROMPT_BEGINNING = 4\n",
    "THREE_SHOT_PROMPT = 5\n",
    "TWO_SHOT_PROMPT = 8\n",
    "\n",
    "PROMPT_NAMES = ['''simpleinstruction''',\n",
    "                '''thinkambiguityfirst''', \n",
    "                '''impersonateexpert''', \n",
    "                '''definedambiguity''', \n",
    "                '''oneshot''', \n",
    "                '''threeshot''', \n",
    "                '''oneshotrationale''', \n",
    "                '''oneshotrationaleexplain''', \n",
    "                '''smarttwoshot''']\n",
    "\n",
    "SYSTEM_PROMPTS = {\n",
    "    'v1': ['''You will be provided with a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”''',\n",
    "           '''You will be provided with a legal statute and a fact pattern. First, define what ambiguity means in this context. Second, if there is ambiguity in the following, respond “True”; if there is no ambiguity, respond “False.”''', \n",
    "           '''Imagine you are a legal expert. You will be provided with a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”''', \n",
    "           '''You will be provided with a legal statute and a fact pattern. Legal ambiguity is when it is unclear whether a general statute applies to a specific fact pattern; both interpretations of the statute as applying or not applying to the fact pattern are feasible. If there is legal ambiguity in whether the following statute applies to the following fact pattern, respond “True”; if there is no ambiguity in whether the following statute applies to the following fact pattern, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”''', \n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”''', \n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.” Then, explain your reasoning.''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. If there is ambiguity, respond “True”; if there is no ambiguity, respond “False.”'''],\n",
    "    'v2': ['''You will be provided with a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. First, explain how you would determine whether such legal ambiguity exists. Second, if there is this legal ambiguity in the following, respond “True”; if there is not this legal ambiguity, respond “False.”''', \n",
    "           '''Imagine you are a legal expert. You will be provided with a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. Legal ambiguity is when it is unclear whether a general statute applies to a specific fact pattern; both interpretations of the statute as applying or not applying to the fact pattern are feasible. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.” Then, explain your reasoning.''',\n",
    "           '''You will be provided with multiple pairs of a legal statute and a fact pattern. Your task is to identify if there is legal ambiguity in the application of the statute to the fact pattern. If there is this legal ambiguity, respond “True”; if there is not this legal ambiguity, respond “False.”''']\n",
    "}\n",
    "\n",
    "USER_PROMPTS = {\n",
    "    'v1': ['''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''',\n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s2}\n",
    "Fact pattern: {f2}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a2}\n",
    "\n",
    "Statute: {s3}\n",
    "Fact pattern: {f3}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a3}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "Explanation: {e1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "Explanation: {e1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: \n",
    "Explanation: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s2}\n",
    "Fact pattern: {f2}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a2}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: '''], \n",
    "    'v2': ['''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''',\n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s}\n",
    "\n",
    "Fact pattern: {f}''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s2}\n",
    "Fact pattern: {f2}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a2}\n",
    "\n",
    "Statute: {s3}\n",
    "Fact pattern: {f3}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a3}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "Explanation: {e1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "Explanation: {e1}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: \n",
    "Explanation: ''', \n",
    "           '''Statute: {s1}\n",
    "Fact pattern: {f1}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a1}\n",
    "\n",
    "Statute: {s2}\n",
    "Fact pattern: {f2}\n",
    "choice: True\n",
    "choice: False\n",
    "A: {a2}\n",
    "\n",
    "Statute: {s}\n",
    "Fact pattern: {f}\n",
    "choice: True\n",
    "choice: False\n",
    "A: ''']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e1782",
   "metadata": {},
   "source": [
    "## GPT model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3de6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94c30d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77591cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_GPT(model, system_prompt, user_input):\n",
    "    client = OpenAI(api_key=MY_API_KEY)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "    chat = client.chat.completions.create(model=model, \n",
    "                                          logprobs=False,\n",
    "                                          messages=messages)\n",
    "    reply = chat.choices[0].message.content\n",
    "    \n",
    "    message_text = 'system: ' + system_prompt + '\\n\\n' + 'user: ' + user_input\n",
    "    return [message_text, reply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdddad7",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "466778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 3\n",
    "FINETUNED_MODEL_START = 2\n",
    "\n",
    "MODEL_NAMES = ['gpt3.5', 'gpt4', 'finetuned']\n",
    "\n",
    "MODELS = ['gpt-3.5-turbo-0125', 'gpt-4-0125-preview', 'ft:gpt-3.5-turbo-0125:ai4life:ambig-finetuned:8xj2T3xT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5de720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2fad010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# programmatic results processing\n",
    "\n",
    "def clean_model_reply(reply):\n",
    "    # take out punctuation, casing\n",
    "    return re.sub(r'[^a-zA-Z0-9]', ' ', reply).lower()\n",
    "\n",
    "def read_model_reply_for_bool(clean_reply):\n",
    "    reply_words = clean_reply.split()\n",
    "    \n",
    "    # use the final \"true/false\" offered by the reply\n",
    "    # particularly relevant when model has longer response e.g. bc asked for explanation\n",
    "    ans = None\n",
    "    for w in reply_words:\n",
    "        if w == 'false':\n",
    "            ans = False\n",
    "        elif w == 'true':\n",
    "            ans = True\n",
    "            \n",
    "    # returns bool if bool in model reply; else, returns None\n",
    "    return ans\n",
    "\n",
    "def followed_instr(prompt, clean_reply):\n",
    "    num_words = len(clean_reply.split()) \n",
    "    if prompt == 'thinkambiguityfirst' or prompt == 'oneshotrationaleexplain':\n",
    "        return num_words > 1 and read_model_reply_for_bool(clean_reply) != None\n",
    "    \n",
    "    return num_words == 1 and read_model_reply_for_bool(clean_reply) != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20a68a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate examples for most few shot prompts, randomly pick unique datapoints other than the current from dataset\n",
    "def gen_few_shot(ds, exclude_i, num_shot):\n",
    "    examples = []\n",
    "    \n",
    "    dataset_len = len(ds)\n",
    "    valid_i = [i for i in range(dataset_len) if i != exclude_i]\n",
    "    \n",
    "    chosen_i = random.sample(valid_i, num_shot)\n",
    "    \n",
    "    # returns list of quadruples (statute, fact_pattern, ambiguity_exists, reason_for_ambiguity) \n",
    "    for new_i in chosen_i:\n",
    "        examples.append((ds['statute'].iloc[new_i], \n",
    "                         ds['fact_pattern'].iloc[new_i], \n",
    "                         ds['ambiguity_exists'].iloc[new_i], \n",
    "                         ds['reason_for_ambiguity'].iloc[new_i]))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd6fd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate examples for smarttwoshot, use previously made smarttwoshot dictionary\n",
    "with open('smarttwoshot.pickle', 'rb') as handle:\n",
    "    TWO_SHOT_DICS = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b2a05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(prompt_vers, run, ds_i_start=0, ds_i_end=NUM_DATASETS, m_i_start=0, m_i_end=NUM_MODELS, p_i_start=0, p_i_end=NUM_PROMPTS):\n",
    "    \n",
    "    pathlib.Path('EXPERIMENTAL_RESULTS/{v}_{r}'.format(v = prompt_vers, r = run)).mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    for ds_i in range(max(0, ds_i_start), min(NUM_DATASETS, ds_i_end)): \n",
    "        dataset = DATASETS[ds_i]\n",
    "        dataset_len = len(dataset)\n",
    "                \n",
    "        for m_i in range(max(0, m_i_start), min(NUM_MODELS, m_i_end)):\n",
    "            model = MODELS[m_i]\n",
    "            \n",
    "            for p_i in range(max(0, p_i_start), min(NUM_PROMPTS, p_i_end)): \n",
    "                results = []\n",
    "                \n",
    "                # calculate preliminary performance stats\n",
    "                correct_counter = 0\n",
    "                follow_counter = 0\n",
    "                \n",
    "                for d_i in tqdm(range(dataset_len)):\n",
    "                    if m_i >= FINETUNED_MODEL_START and d_i in TRAIN_INDS[DATASET_NAMES[ds_i]]:\n",
    "                        results.append(['training data point; skipped', '', 'NONE', 'NONE'])\n",
    "                    \n",
    "                    else: \n",
    "                        system_prompt = SYSTEM_PROMPTS[prompt_vers][p_i]\n",
    "\n",
    "                        if p_i < IN_CONTEXT_PROMPT_BEGINNING:\n",
    "                            user_prompt = USER_PROMPTS[prompt_vers][p_i].format(s = dataset['statute'].iloc[d_i], \n",
    "                                                                                f = dataset['fact_pattern'].iloc[d_i])\n",
    "                        elif p_i == THREE_SHOT_PROMPT:\n",
    "                            three_shot_examples = gen_few_shot(dataset, d_i, 3)\n",
    "                            user_prompt = USER_PROMPTS[prompt_vers][p_i].format(s1 = three_shot_examples[0][0], \n",
    "                                                                                f1 = three_shot_examples[0][1],\n",
    "                                                                                a1 = three_shot_examples[0][2],\n",
    "                                                                                e1 = three_shot_examples[0][3],\n",
    "                                                                                s2 = three_shot_examples[1][0], \n",
    "                                                                                f2 = three_shot_examples[1][1],\n",
    "                                                                                a2 = three_shot_examples[1][2],\n",
    "                                                                                e2 = three_shot_examples[1][3],\n",
    "                                                                                s3 = three_shot_examples[2][0], \n",
    "                                                                                f3 = three_shot_examples[2][1],\n",
    "                                                                                a3 = three_shot_examples[2][2],\n",
    "                                                                                e3 = three_shot_examples[2][3],\n",
    "                                                                                s = dataset['statute'].iloc[d_i], \n",
    "                                                                                f = dataset['fact_pattern'].iloc[d_i])\n",
    "                        elif p_i == TWO_SHOT_PROMPT:\n",
    "                            user_prompt = USER_PROMPTS[prompt_vers][p_i].format(s1 = TWO_SHOT_DICS[ds_i][d_i][0][0], \n",
    "                                                                                f1 = TWO_SHOT_DICS[ds_i][d_i][0][1],\n",
    "                                                                                a1 = TWO_SHOT_DICS[ds_i][d_i][0][2],\n",
    "                                                                                e1 = TWO_SHOT_DICS[ds_i][d_i][0][3],\n",
    "                                                                                s2 = TWO_SHOT_DICS[ds_i][d_i][1][0], \n",
    "                                                                                f2 = TWO_SHOT_DICS[ds_i][d_i][1][1],\n",
    "                                                                                a2 = TWO_SHOT_DICS[ds_i][d_i][1][2],\n",
    "                                                                                e2 = TWO_SHOT_DICS[ds_i][d_i][1][3],\n",
    "                                                                                s = dataset['statute'].iloc[d_i], \n",
    "                                                                                f = dataset['fact_pattern'].iloc[d_i])\n",
    "                        else:\n",
    "                            one_shot_example = gen_few_shot(dataset, d_i, 1)[0]\n",
    "                            user_prompt = USER_PROMPTS[prompt_vers][p_i].format(s1 = one_shot_example[0],\n",
    "                                                                                f1 = one_shot_example[1],\n",
    "                                                                                a1 = one_shot_example[2],\n",
    "                                                                                e1 = one_shot_example[3],\n",
    "                                                                                s = dataset['statute'].iloc[d_i], \n",
    "                                                                                f = dataset['fact_pattern'].iloc[d_i])\n",
    "\n",
    "                        res = query_GPT(model, system_prompt, user_prompt)\n",
    "                        model_res_clean = clean_model_reply(res[1])\n",
    "                        res_bool = read_model_reply_for_bool(model_res_clean)\n",
    "                        \n",
    "                        if res_bool != None:\n",
    "                            res.append(res_bool)\n",
    "                            if res_bool == dataset['ambiguity_exists'].iloc[d_i]:\n",
    "                                correct_counter += 1\n",
    "                        \n",
    "                        res_fi = followed_instr(PROMPT_NAMES[p_i], model_res_clean)\n",
    "                        res.append(res_fi)\n",
    "                        if res_fi:\n",
    "                            follow_counter += 1\n",
    "                                                \n",
    "                        results.append(res)\n",
    "                \n",
    "                csv_file_name = 'EXPERIMENTAL_RESULTS/{v}_{r}/{ds}_{m}_{p}.csv'.format(v = prompt_vers,\n",
    "                                                                                       r = run,\n",
    "                                                                                       ds = DATASET_NAMES[ds_i],\n",
    "                                                                                       m = MODEL_NAMES[m_i],\n",
    "                                                                                       p = PROMPT_NAMES[p_i])\n",
    "                with open(csv_file_name, 'w') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow(['model_input', 'model_output', 'model_output_processed', 'followed_instr'])\n",
    "                    csv_writer.writerows(results)\n",
    "                    \n",
    "                num_datapts = dataset_len\n",
    "                if m_i >= FINETUNED_MODEL_START:\n",
    "                    num_datapts -= len(TRAIN_INDS[DATASET_NAMES[ds_i]])\n",
    "                    \n",
    "                print('{ds} {m} {p} acc: {acc}\\n'.format(ds = DATASET_NAMES[ds_i],\n",
    "                                                         m = MODEL_NAMES[m_i],\n",
    "                                                         p = PROMPT_NAMES[p_i],\n",
    "                                                         acc = correct_counter / num_datapts))\n",
    "\n",
    "                print('{ds} {m} {p} fi: {fi}\\n'.format(ds = DATASET_NAMES[ds_i],\n",
    "                                                       m = MODEL_NAMES[m_i],\n",
    "                                                       p = PROMPT_NAMES[p_i],\n",
    "                                                       fi = follow_counter / num_datapts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e449273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [00:57<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp simpleinstruction acc: 0.6563706563706564\n",
      "\n",
      "sara finetunedexp simpleinstruction fi: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [03:21<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp thinkambiguityfirst acc: 0.1583011583011583\n",
      "\n",
      "sara finetunedexp thinkambiguityfirst fi: 0.2471042471042471\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [01:02<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp impersonateexpert acc: 0.6525096525096525\n",
      "\n",
      "sara finetunedexp impersonateexpert fi: 0.9922779922779923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [00:58<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp definedambiguity acc: 0.6254826254826255\n",
      "\n",
      "sara finetunedexp definedambiguity fi: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [01:01<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp oneshot acc: 0.6254826254826255\n",
      "\n",
      "sara finetunedexp oneshot fi: 0.9806949806949807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [01:03<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp threeshot acc: 0.6293436293436293\n",
      "\n",
      "sara finetunedexp threeshot fi: 0.9922779922779923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [01:07<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp oneshotrationale acc: 0.5598455598455598\n",
      "\n",
      "sara finetunedexp oneshotrationale fi: 0.9845559845559846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [01:58<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp oneshotrationaleexplain acc: 0.7258687258687259\n",
      "\n",
      "sara finetunedexp oneshotrationaleexplain fi: 0.915057915057915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 310/310 [00:59<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sara finetunedexp smarttwoshot acc: 0.6254826254826255\n",
      "\n",
      "sara finetunedexp smarttwoshot fi: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [01:54<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp simpleinstruction acc: 0.4222222222222222\n",
      "\n",
      "echr finetunedexp simpleinstruction fi: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [06:33<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp thinkambiguityfirst acc: 0.08888888888888889\n",
      "\n",
      "echr finetunedexp thinkambiguityfirst fi: 0.22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [01:58<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp impersonateexpert acc: 0.42\n",
      "\n",
      "echr finetunedexp impersonateexpert fi: 0.9977777777777778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [01:57<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp definedambiguity acc: 0.44666666666666666\n",
      "\n",
      "echr finetunedexp definedambiguity fi: 0.9977777777777778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [02:51<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp oneshot acc: 0.4111111111111111\n",
      "\n",
      "echr finetunedexp oneshot fi: 0.9333333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [03:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp threeshot acc: 0.36666666666666664\n",
      "\n",
      "echr finetunedexp threeshot fi: 0.9733333333333334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [02:33<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp oneshotrationale acc: 0.4111111111111111\n",
      "\n",
      "echr finetunedexp oneshotrationale fi: 0.98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [04:50<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp oneshotrationaleexplain acc: 0.31777777777777777\n",
      "\n",
      "echr finetunedexp oneshotrationaleexplain fi: 0.9888888888888889\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [02:42<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echr finetunedexp smarttwoshot acc: 0.34444444444444444\n",
      "\n",
      "echr finetunedexp smarttwoshot fi: 0.9622222222222222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline('v2', 'r4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
