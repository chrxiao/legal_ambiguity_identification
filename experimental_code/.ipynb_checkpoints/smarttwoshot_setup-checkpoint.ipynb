{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd9e692",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8274f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e14f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATASETS = 2\n",
    "\n",
    "DATASET_NAMES = ['sara', 'echr']\n",
    "\n",
    "sara_df = pd.read_csv('DATASETS/sara_annotated.csv')\n",
    "echr_df = pd.read_csv('DATASETS/echr_annotated.csv')\n",
    "\n",
    "DATASETS = [sara_df, echr_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff88b0",
   "metadata": {},
   "source": [
    "## Smart 2-shot dictionary generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e329110",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(curr_i, curr_embed, embedding_space):\n",
    "    closest_dist = np.finfo(np.float32).max\n",
    "    closest_i = -1\n",
    "    \n",
    "    for d_i, embed in embedding_space.items():\n",
    "        if d_i == curr_i:\n",
    "            continue\n",
    "        \n",
    "        euclid_dist = np.linalg.norm(curr_embed - embed)\n",
    "        if euclid_dist < closest_dist:\n",
    "            closest_dist = euclid_dist\n",
    "            closest_i = d_i\n",
    "        \n",
    "    return closest_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f395cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns dictionary matching each datapt to its few_shot examples \n",
    "def gen_similar_two_shot(dataset):     \n",
    "    # make dicts of embeddings\n",
    "    ambig_statute_fact_pattern_embeddings = {}\n",
    "    non_ambig_statute_fact_pattern_embeddings = {}\n",
    "    ambig_fact_pattern_embeddings = {}\n",
    "    non_ambig_fact_pattern_embeddings = {}\n",
    "    \n",
    "    for d_i in tqdm(range(len(dataset))):\n",
    "        statute_fact_pattern = '''Statute: {s}\n",
    "Fact pattern: {f}'''.format(s = dataset['statute'].iloc[d_i], \n",
    "                            f = dataset['fact_pattern'].iloc[d_i])\n",
    "        \n",
    "        if dataset['ambiguity_exists'].iloc[d_i] == True:\n",
    "            ambig_statute_fact_pattern_embeddings[d_i] = sentence_embedding_model.encode(statute_fact_pattern)\n",
    "            ambig_fact_pattern_embeddings[d_i] = sentence_embedding_model.encode(dataset['fact_pattern'].iloc[d_i])\n",
    "        elif dataset['ambiguity_exists'].iloc[d_i] == False:\n",
    "            non_ambig_statute_fact_pattern_embeddings[d_i] = sentence_embedding_model.encode(statute_fact_pattern)\n",
    "            non_ambig_fact_pattern_embeddings[d_i] = sentence_embedding_model.encode(dataset['fact_pattern'].iloc[d_i])\n",
    "        else: \n",
    "            print(\"DATASET ERROR\")\n",
    "    \n",
    "    # gen similar two shot\n",
    "    two_shot = {}\n",
    "    for d_i in tqdm(range(len(dataset))):\n",
    "        potential_examples = {'True': [], 'False': []}  # stores inds\n",
    "\n",
    "        d_statute = dataset['statute'].iloc[d_i]\n",
    "\n",
    "        # since datasets are sorted by statute, we can just iterate before and after datapt_i\n",
    "        for pre_i in range(d_i-1, -1, -1):\n",
    "            if dataset['statute'].iloc[pre_i] == d_statute:\n",
    "                potential_examples[str(dataset['ambiguity_exists'].iloc[pre_i])].append(pre_i)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        for post_i in range(d_i+1, len(dataset)):\n",
    "            if dataset['statute'].iloc[post_i] == d_statute:\n",
    "                potential_examples[str(dataset['ambiguity_exists'].iloc[post_i])].append(post_i)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        ambig_i = -1\n",
    "        non_ambig_i = -1\n",
    "\n",
    "        if len(potential_examples['True']) == 1:\n",
    "            ambig_i = potential_examples['True'][0]\n",
    "        elif len(potential_examples['True']) == 0:\n",
    "            ambig_i = most_similar(d_i, \n",
    "                                   ambig_statute_fact_pattern_embeddings[d_i] if d_i in ambig_statute_fact_pattern_embeddings else non_ambig_statute_fact_pattern_embeddings[d_i], \n",
    "                                   ambig_statute_fact_pattern_embeddings)\n",
    "        else: \n",
    "            potential_example_fact_pattern_embeddings = {}\n",
    "            for pe_i in potential_examples['True']:\n",
    "                potential_example_fact_pattern_embeddings[pe_i] = ambig_fact_pattern_embeddings[pe_i]\n",
    "\n",
    "            ambig_i = most_similar(d_i,\n",
    "                                   ambig_fact_pattern_embeddings[d_i] if d_i in ambig_fact_pattern_embeddings else non_ambig_fact_pattern_embeddings[d_i],\n",
    "                                   potential_example_fact_pattern_embeddings)\n",
    "            \n",
    "    \n",
    "        if len(potential_examples['False']) == 1:\n",
    "            non_ambig_i = potential_examples['False'][0]\n",
    "        elif len(potential_examples['False']) == 0:\n",
    "            non_ambig_i = most_similar(d_i, \n",
    "                                       ambig_statute_fact_pattern_embeddings[d_i] if d_i in ambig_statute_fact_pattern_embeddings else non_ambig_statute_fact_pattern_embeddings[d_i], \n",
    "                                       non_ambig_statute_fact_pattern_embeddings)\n",
    "        else:\n",
    "            potential_example_fact_pattern_embeddings = {}\n",
    "            for pe_i in potential_examples['False']:\n",
    "                potential_example_fact_pattern_embeddings[pe_i] = non_ambig_fact_pattern_embeddings[pe_i]\n",
    "\n",
    "            non_ambig_i = most_similar(d_i,\n",
    "                                       ambig_fact_pattern_embeddings[d_i] if d_i in ambig_fact_pattern_embeddings else non_ambig_fact_pattern_embeddings[d_i],\n",
    "                                       potential_example_fact_pattern_embeddings)\n",
    "            \n",
    "        if ambig_i == -1 or non_ambig_i == -1:\n",
    "            print(\"ERROR GEN SIMILAR TWO SHOT\")\n",
    "            \n",
    "        # present in-context examples as non-ambiguous first, then ambiguous\n",
    "        two_shot[d_i] = [(dataset['statute'].iloc[non_ambig_i],\n",
    "                          dataset['fact_pattern'].iloc[non_ambig_i], \n",
    "                          dataset['ambiguity_exists'].iloc[non_ambig_i],\n",
    "                          dataset['reason_for_ambiguity'].iloc[non_ambig_i]), \n",
    "                         (dataset['statute'].iloc[ambig_i],\n",
    "                          dataset['fact_pattern'].iloc[ambig_i], \n",
    "                          dataset['ambiguity_exists'].iloc[ambig_i],\n",
    "                          dataset['reason_for_ambiguity'].iloc[ambig_i])]\n",
    "    \n",
    "    return two_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a590441",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWO_SHOT_DICS = [gen_similar_two_shot(dataset) for dataset in DATASETS]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
